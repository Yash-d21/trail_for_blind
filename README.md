#Trail - AI Assistance for the Visually Impaired

Trail is an AI-powered mobile app designed to assist visually impaired individuals by reading text aloud, identifying objects, providing navigation guidance, and describing surroundings in real-time. Built using Flutter, Google ML Kit, and Firebase, Trail enhances accessibility and independence.

#Features

Document Reader – Extracts and reads text using OCR.

Object Recognition – Identifies objects in the surroundings.

Facial Recognition – Detects and announces known faces.

Environment Description – Captures and describes the environment.

Path Finder – Provides real-time navigation.

Voice Commands – Allows interaction through speech.

Multi-Language Support – Uses Google Translate for accessibility.

Real-Time AI Assistance – Processes user input quickly for seamless assistance.

#Tech Stack

Frontend: Flutter

AI & ML Models: Google ML Kit, TensorFlow Lite

Backend: Firebase Firestore, Google Cloud Functions

APIs: Google Vision API, Google Maps API, Google Text-to-Speech & Speech-to-Text

Contribution & Development

This project is being developed as part of Google Summer of Code (GSoC) 2025. Contributions are welcome! Feel free to fork this repo, open issues, and submit pull requests.
