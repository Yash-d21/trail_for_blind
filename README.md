# **Trail** 🚀

**An AI-powered accessibility app for the visually impaired, developed for GSoC 2025.**

## **Overview**
Trail is a mobile app that helps visually impaired individuals navigate the world with ease. It leverages AI and Google-powered modules to provide real-time text reading, object recognition, facial detection, navigation assistance, and environment description.

## **Features**
- 📖 **Document Reader** – Reads text from images using OCR (Google Vision API)
- 🔍 **Object Recognition** – Identifies objects in real time with ML Kit / TensorFlow Lite
- 🗣 **Voice Commands** – Hands-free interaction via Google Assistant integration
- 🧭 **Path Finder** – Navigation assistance using Google Maps API
- 🎭 **Facial Recognition** – Identifies people and announces names
- 🌍 **Multi-Language Support** – Uses Google Translate for accessibility

## **Technologies Used**
- **Frontend**: Flutter
- **AI/ML**: Google ML Kit, TensorFlow Lite
- **Backend**: Firebase Firestore, Google Cloud Functions
- **Speech Processing**: Google Text-to-Speech & Speech-to-Text
- **Navigation**: Google Maps API
- **Authentication**: Firebase Auth

## **Installation**
```bash
# Clone the repository
git clone https://github.com/yourusername/trail.git

# Navigate into the project folder
cd trail

# Install dependencies
flutter pub get

# Run the app
flutter run
```

## **Future Development**
- 🔗 Integration with accessibility APIs for deeper system-wide support
- 📢 Advanced AI-driven voice assistant for hands-free interaction
- 📊 Enhanced analytics to track user engagement and app performance

## **Contributing**
We welcome contributions! Feel free to fork the repository, raise issues, and submit pull requests. 🙌

## **License**
This project is licensed under the **MIT License**.

---
**Made with ❤️ for GSoC 2025**
