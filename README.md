# **Trail** ğŸš€

**An AI-powered accessibility app for the visually impaired, developed for GSoC 2025.**

## **Overview**
Trail is a mobile app that helps visually impaired individuals navigate the world with ease. It leverages AI and Google-powered modules to provide real-time text reading, object recognition, facial detection, navigation assistance, and environment description.

## **Features**
- ğŸ“– **Document Reader** â€“ Reads text from images using OCR (Google Vision API)
- ğŸ” **Object Recognition** â€“ Identifies objects in real time with ML Kit / TensorFlow Lite
- ğŸ—£ **Voice Commands** â€“ Hands-free interaction via Google Assistant integration
- ğŸ§­ **Path Finder** â€“ Navigation assistance using Google Maps API
- ğŸ­ **Facial Recognition** â€“ Identifies people and announces names
- ğŸŒ **Multi-Language Support** â€“ Uses Google Translate for accessibility

## **Technologies Used**
- **Frontend**: Flutter
- **AI/ML**: Google ML Kit, TensorFlow Lite
- **Backend**: Firebase Firestore, Google Cloud Functions
- **Speech Processing**: Google Text-to-Speech & Speech-to-Text
- **Navigation**: Google Maps API
- **Authentication**: Firebase Auth

## **Installation**
```bash
# Clone the repository
git clone https://github.com/yourusername/trail.git

# Navigate into the project folder
cd trail

# Install dependencies
flutter pub get

# Run the app
flutter run
```

## **Future Development**
- ğŸ”— Integration with accessibility APIs for deeper system-wide support
- ğŸ“¢ Advanced AI-driven voice assistant for hands-free interaction
- ğŸ“Š Enhanced analytics to track user engagement and app performance

## **Contributing**
We welcome contributions! Feel free to fork the repository, raise issues, and submit pull requests. ğŸ™Œ

## **License**
This project is licensed under the **MIT License**.

---
**Made with â¤ï¸ for GSoC 2025**
